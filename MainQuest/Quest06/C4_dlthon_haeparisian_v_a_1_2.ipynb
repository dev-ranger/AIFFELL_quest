{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DILLU-n3nVqM"
   },
   "source": [
    "# DL톤 해파리 분류기\n",
    "아이펠 코어 12기 팀: 해파리지앵  \n",
    "@author: Hyeseung Lee  \n",
    "Created: 2025-04-01  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiG-6OW6nbTR"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "해파리 분류기 노트북 코드 요약 설명\n",
    "이 노트북 코드는 딥러닝을 사용하여 해파리 이미지를 분류하는 모델을 구축하고 훈련하는 과정을 담고 있습니다. 주요 기능과 단계는 다음과 같습니다.\n",
    "\n",
    "1. 데이터 준비 및 전처리:\n",
    "\n",
    "Google Drive에 저장된 해파리 이미지 데이터셋을 불러옵니다. 데이터셋은 훈련, 검증, 테스트셋으로 나뉘어져 있습니다.\n",
    "load_dataset_from_directory 함수를 사용하여 이미지를 로드하고 크기를 조정합니다.\n",
    "count_images_per_class 함수를 사용하여 각 클래스별 이미지 개수를 확인하고 데이터 분포를 파악합니다.\n",
    "get_class_labels 함수를 사용하여 디렉토리 구조를 기반으로 클래스 레이블을 자동으로 추출합니다.\n",
    "2. 데이터 증강:\n",
    "\n",
    "AugmentationManager 클래스를 사용하여 훈련 이미지에 대한 데이터 증강 파이프라인을 생성합니다.\n",
    "회전, 이동, 확대/축소, 수평 뒤집기 등 다양한 증강 기법을 적용하여 모델의 일반화 성능을 향상시킵니다.\n",
    "apply_augmentation 함수를 사용하여 증강된 이미지를 생성하고 시각화하여 증강 결과를 확인합니다.\n",
    "gaussian_blur, salt_and_pepper_noise, gaussian_noise 함수를 통해 추가적인 노이즈 증강 기법을 적용할 수 있습니다.\n",
    "3. 모델 구축 및 훈련:\n",
    "\n",
    "JellyfishClassifier 클래스를 사용하여 해파리 분류 모델을 정의합니다.\n",
    "EfficientNet, MobileNet, ResNet 등 다양한 사전 훈련된 모델을 기반으로 모델을 구축할 수 있습니다.\n",
    "fit 메서드를 사용하여 모델을 훈련합니다. 훈련 과정에서 검증 데이터를 사용하여 모델 성능을 평가하고 조기 종료 및 체크포인트 기능을 활용하여 최적의 모델을 저장합니다.\n",
    "훈련 중에는 TqdmCallback을 사용하여 진행 상황을 시각적으로 표시합니다.\n",
    "ReduceLROnPlateau 콜백을 사용하여 검증 손실이 정체될 경우 학습률을 조정합니다.\n",
    "4. 모델 평가 및 시각화:\n",
    "\n",
    "evaluate 메서드를 사용하여 테스트 데이터셋에 대한 모델 성능을 평가합니다. 정확도, F1 점수, 엔트로피 등 다양한 지표를 사용하여 모델 성능을 측정합니다.\n",
    "Test Time Augmentation (TTA) 기법을 적용하여 모델 예측의 정확도를 높일 수 있습니다.\n",
    "k_fold_cross_validation 메서드를 사용하여 K-fold 교차 검증을 수행하고 모델의 일반화 성능을 평가합니다.\n",
    "plot_confusion_matrix 함수를 사용하여 혼동 행렬을 시각화하고 모델의 예측 오류를 분석합니다.\n",
    "plot_training_history 함수를 사용하여 훈련 과정에서의 손실 및 정확도 변화를 시각화합니다.\n",
    "5. 모델 저장 및 로드:\n",
    "\n",
    "save_model 메서드를 사용하여 훈련된 모델을 파일로 저장합니다.\n",
    "load_model 메서드를 사용하여 저장된 모델을 불러와서 사용할 수 있습니다.\n",
    "6. 예측:\n",
    "\n",
    "predict 메서드를 사용하여 새로운 이미지에 대한 예측을 수행합니다.\n",
    "TTA 기법을 적용하여 예측 정확도를 높일 수 있습니다.\n",
    "요약:\n",
    "\n",
    "이 노트북 코드는 데이터 준비, 증강, 모델 구축, 훈련, 평가, 시각화, 저장, 로드, 예측 등 딥러닝 모델 개발의 전 과정을 포함하고 있습니다. 다양한 기능과 옵션을 제공하여 사용자가 해파리 이미지 분류 모델을 효과적으로 구축하고 실험할 수 있도록 지원합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZpvnvjongsQ"
   },
   "source": [
    "# Install libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYcrVUjbnURJ",
    "outputId": "c44dc95a-217d-46f3-c96d-e3235be62e42"
   },
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrkrSfdFnoX4",
    "outputId": "07952689-518e-4a7c-f15e-dd74ef4564e5"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NktztUYrnrNA",
    "outputId": "414907a6-cc66-41e3-fcb9-c2666e7fa910"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPsZ_0F0nrrK",
    "outputId": "dd4e83db-b503-4925-d8b3-61e4387799aa"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-image --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jp9gxPUnnvGX",
    "outputId": "32b3983a-d3f1-4fc0-bc3d-cdc68f0fe2ca"
   },
   "outputs": [],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsQkVZQfn271"
   },
   "source": [
    "## 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Cce-tsAnvUs"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "from tqdm.auto import tqdm  # Import tqdm.auto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import math\n",
    "import random\n",
    "import glob\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models, callbacks, applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import cv2\n",
    "import albumentations as A  # Import Albumentations\n",
    "\n",
    "### merge from Wongu\n",
    "import kagglehub\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbCallback\n",
    "from datetime import datetime\n",
    "\n",
    "# from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq8LfOjaoH_Q"
   },
   "source": [
    "## Common functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unR2srzGoop9"
   },
   "source": [
    "## Prepare Dataset\n",
    "\n",
    "google drive 의 구조를 맞춰주세요.\n",
    "\n",
    "원본 이미지 데이터셋 :\n",
    "/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/Train_Test_Valid\n",
    "\n",
    "클린업 이미지 데이터셋\n",
    "/content/drive/MyDrive/ColabNotebooks/ToyDatasets/jellyfish-dataset/Clean_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGJ9OYkunviW"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "def load_dataset_from_directory(directory, img_size=(224, 224), batch_size=32, flatten=False):\n",
    "    \"\"\"폴더에서 RGB 이미지 데이터셋을 로드하는 함수 (최신 TensorFlow 방식)\"\"\"\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb',\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        labels='inferred',\n",
    "        label_mode='int'\n",
    "    )\n",
    "\n",
    "    # 클래스 이름 가져오기\n",
    "    class_names = dataset.class_names\n",
    "    class_dict = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "    # 데이터셋 전처리 (정규화)\n",
    "    def preprocess(images, labels):\n",
    "        images = tf.cast(images, tf.float32) / 255.0\n",
    "        return images, labels\n",
    "\n",
    "    dataset = dataset.map(preprocess)\n",
    "\n",
    "    # 전체 데이터 메모리에 로드\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        X_list.append(images.numpy())\n",
    "        y_list.append(labels.numpy())\n",
    "\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "    # 필요한 경우 평탄화(flatten)\n",
    "    if flatten:\n",
    "        X = X.reshape(X.shape[0], -1)  # (n_samples, height*width*channels)\n",
    "\n",
    "    # 그레이스케일 특화 코드\n",
    "    # 기존: elif color_mode == 'grayscale': X = X[..., 0]\n",
    "\n",
    "    return X, y, class_dict\n",
    "\n",
    "class AugmentationManager:\n",
    "    \"\"\"데이터 증강을 관리하는 클래스\n",
    "\n",
    "    - 증강 파이프라인(ImageDegenerator객체)를 생성하는 역할\n",
    "    - 즉, 어떤 증강 방법들을 사용할지 설정(configuration)하는 부분\n",
    "    - 실제로 이미지에 증강을 적용하지는 않음\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def create_train_augmentation(rotation_range=20, width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2, zoom_range=0.2,\n",
    "                                 horizontal_flip=True, vertical_flip=False,\n",
    "                                 fill_mode='nearest'):\n",
    "        '''\n",
    "        Train Time Augmentation 설정\n",
    "\n",
    "        Args:\n",
    "            rotation_range (int): 회전 각도 범위\n",
    "            width_shift_range (float): 가로 이동 범위\n",
    "            height_shift_range (float): 세로 이동 범위\n",
    "            zoom_range (float): 확대/축소 범위\n",
    "            horizontal_flip (bool): 수평 뒤집기 적용 여부\n",
    "            vertical_flip (bool): 수직 뒤집기 적용 여부\n",
    "            fill_mode (str): 채우기 모드\n",
    "\n",
    "        Returns:\n",
    "            ImageDataGenerator: 데이터 증강이 적용된 제너레이터\n",
    "        '''\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            # rescale=1./255,\n",
    "            rotation_range=rotation_range,\n",
    "            width_shift_range=width_shift_range,\n",
    "            height_shift_range=height_shift_range,\n",
    "            zoom_range=zoom_range,\n",
    "            horizontal_flip=horizontal_flip,\n",
    "            vertical_flip=vertical_flip,\n",
    "            fill_mode=fill_mode\n",
    "        )\n",
    "\n",
    "        return train_datagen\n",
    "\n",
    "    @staticmethod\n",
    "    def create_test_augmentation(n_augmentations=3):\n",
    "        '''\n",
    "        Test Time Augmentation 설정 - 가벼운 변형만 적용\n",
    "\n",
    "        Args:\n",
    "            n_augmentations (int): TTA에 사용할 증강 횟수\n",
    "\n",
    "        Returns:\n",
    "            list: 데이터 제너레이터 리스트\n",
    "        '''\n",
    "        # 기본 제너레이터 (변형 없음)\n",
    "        base_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        # 증강 제너레이터들\n",
    "        tta_datagens = [base_datagen]\n",
    "\n",
    "        if n_augmentations >= 1:\n",
    "            # 수평 뒤집기\n",
    "            tta_datagens.append(ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                horizontal_flip=True\n",
    "            ))\n",
    "\n",
    "        if n_augmentations >= 2:\n",
    "            # 약간 회전\n",
    "            tta_datagens.append(ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                rotation_range=10\n",
    "            ))\n",
    "\n",
    "        if n_augmentations >= 3:\n",
    "            # 약간 확대\n",
    "            tta_datagens.append(ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                zoom_range=0.1\n",
    "            ))\n",
    "\n",
    "        return tta_datagens[:n_augmentations+1]  # 기본 데이터젠도 포함\n",
    "\n",
    "def apply_augmentation(image, datagen, num_samples=5,\n",
    "                       apply_gaussian_blur=True, gaussian_blur_prob=0.5,\n",
    "                       apply_salt_and_pepper=False, salt_and_pepper_prob=0.15,\n",
    "                       apply_gaussian_noise=True, gaussian_noise_prob=0.5,\n",
    "                       gaussian_noise_mean=0.0, gaussian_noise_std=0.05,\n",
    "                       apply_elastic_transform=True, elastic_transform_prob=0.5,\n",
    "                       apply_random_crop_resize=True, random_crop_resize_prob=0.5,\n",
    "                       apply_brightness_adjust=True, brightness_adjust_prob=0.5,\n",
    "                       apply_contrast_adjust=True, contrast_adjust_prob=0.5,\n",
    "                       apply_hue_adjust=True, hue_adjust_prob=0.5\n",
    "                       ):\n",
    "    \"\"\"\n",
    "    이미지에 다양한 증강 기법을 적용합니다.\n",
    "\n",
    "    Args:\n",
    "        image: 입력 이미지 (NumPy 배열).\n",
    "        datagen: ImageDataGenerator 객체.\n",
    "        num_samples: 생성할 증강 이미지 샘플 수 (기본값: 5).\n",
    "        apply_gaussian_blur: 가우시안 블러 적용 여부 (기본값: True).\n",
    "        gaussian_blur_prob: 가우시안 블러 적용 확률 (기본값: 0.5).\n",
    "        apply_salt_and_pepper: Salt and Pepper 노이즈 적용 여부 (기본값: True).\n",
    "        salt_and_pepper_prob: Salt and Pepper 노이즈 적용 확률 (기본값: 0.15).\n",
    "        apply_gaussian_noise: 가우시안 노이즈 적용 여부 (기본값: True).\n",
    "        gaussian_noise_prob: 가우시안 노이즈 적용 확률 (기본값: 0.5).\n",
    "        gaussian_noise_mean: 가우시안 노이즈의 평균 (기본값: 0.0).\n",
    "        gaussian_noise_std: 가우시안 노이즈의 표준 편차 (기본값: 0.05).\n",
    "\n",
    "        apply_elastic_transform: 탄력적 변형 적용 여부 (기본값: True).\n",
    "        elastic_transform_prob: 탄력적 변형 적용 확률 (기본값: 0.5).\n",
    "        apply_random_crop_resize: 랜덤 Cropping & Resizing 적용 여부 (기본값: True).\n",
    "        random_crop_resize_prob: 랜덤 Cropping & Resizing 적용 확률 (기본값: 0.5).\n",
    "        apply_brightness_adjust: 밝기 조절 적용 여부 (기본값: True).\n",
    "        brightness_adjust_prob: 밝기 조절 적용 확률 (기본값: 0.5).\n",
    "        apply_contrast_adjust: 대비 조절 적용 여부 (기본값: True).\n",
    "        contrast_adjust_prob: 대비 조절 적용 확률 (기본값: 0.5).\n",
    "        apply_hue_adjust: 색조 조절 적용 여부 (기본값: True).\n",
    "        hue_adjust_prob: 색조 조절 적용 확률 (기본값: 0.5).\n",
    "\n",
    "    Returns:\n",
    "        증강된 이미지 리스트.\n",
    "    \"\"\"\n",
    "    # 이미지 데이터 타입 확인 및 정규화 (필요한 경우),\n",
    "    if image.dtype == np.uint8:\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "\n",
    "    # 이미지 차원 확인 및 처리\n",
    "    if len(image.shape) == 2:  # 흑백 이미지면\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "    # 배치 차원 추가\n",
    "    image_batch = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # 증강 이미지 생성\n",
    "    augmented_images = []\n",
    "    for _ in range(num_samples):\n",
    "        aug_generator = datagen.flow(image_batch, batch_size=1)\n",
    "        aug_image = next(aug_generator)[0]\n",
    "\n",
    "        # 차원 처리 (원본 이미지와 동일한 차원으로)\n",
    "        if len(image.shape) == 3 and len(aug_image.shape) == 4:  # 컬러 이미지 처리\n",
    "            aug_image = aug_image[:, :, :, 0]  # 채널 차원 제거\n",
    "        elif len(image.shape) == 2 and len(aug_image.shape) == 3: # 흑백 이미지 처리\n",
    "            aug_image = aug_image[:, :, 0]  # 채널 차원 제거\n",
    "\n",
    "        # Gaussian Blur 적용 선택적 적용\n",
    "        if apply_gaussian_blur and random.random() < gaussian_blur_prob:    # 값이 0.5 면 이미지의 50%에만 확률적 적용\n",
    "            aug_image = gaussian_blur(aug_image)\n",
    "\n",
    "        # Salt and Pepper 노이즈 선택적 적용\n",
    "        if apply_salt_and_pepper and random.random() < salt_and_pepper_prob: # 값이 0.05 면 이미지의 5%만 적용\n",
    "            aug_image = salt_and_pepper_noise(aug_image)\n",
    "\n",
    "        # Apply Gaussian Noise with probability and clip\n",
    "        if apply_gaussian_noise and random.random() < gaussian_noise_prob:\n",
    "            aug_image = gaussian_noise(aug_image, gaussian_noise_mean, gaussian_noise_std)\n",
    "\n",
    "        # 탄력적 변형 적용 (Albumentations 사용) and clip\n",
    "        if apply_elastic_transform and random.random() < elastic_transform_prob:\n",
    "            transform = A.ElasticTransform(p=1, alpha=random.uniform(30, 70), sigma=random.uniform(4, 6),\n",
    "                                          alpha_affine=random.uniform(0, 10),\n",
    "                                          border_mode=cv2.BORDER_REFLECT_101)\n",
    "            aug_image = transform(image=aug_image)['image']\n",
    "            aug_image = np.clip(aug_image, 0.0, 1.0)  # Clip after elastic transform\n",
    "\n",
    "        # 랜덤 Cropping & Resizing 적용\n",
    "        if apply_random_crop_resize and random.random() < random_crop_resize_prob:\n",
    "            # 랜덤으로 자를 영역 크기 결정 (원본 이미지의 70%~100% 크기)\n",
    "            crop_size = random.randint(int(aug_image.shape[0] * 0.7), aug_image.shape[0])\n",
    "            # 랜덤으로 자를 시작 위치 결정\n",
    "            crop_x = random.randint(0, aug_image.shape[0] - crop_size)\n",
    "            crop_y = random.randint(0, aug_image.shape[1] - crop_size)\n",
    "            # 이미지 자르기\n",
    "            cropped_image = aug_image[crop_x:crop_x + crop_size, crop_y:crop_y + crop_size]\n",
    "            # 원본 크기로 리사이징\n",
    "            aug_image = cv2.resize(cropped_image, (aug_image.shape[0], aug_image.shape[1]))\n",
    "\n",
    "        # 밝기 조절 적용\n",
    "        if apply_brightness_adjust and random.random() < brightness_adjust_prob:\n",
    "            aug_image = tf.image.adjust_brightness(aug_image, delta=random.uniform(-0.2, 0.2))  # 밝기 랜덤 조절\n",
    "            aug_image = tf.clip_by_value(aug_image, 0.0, 1.0)  # Clip brightness\n",
    "\n",
    "\n",
    "        # 대비 조절 적용\n",
    "        if apply_contrast_adjust and random.random() < contrast_adjust_prob:\n",
    "            aug_image = tf.image.adjust_contrast(aug_image, contrast_factor=random.uniform(0.8, 1.2))  # 대비 랜덤 조절\n",
    "            aug_image = tf.clip_by_value(aug_image, 0.0, 1.0)  # Clip contrast\n",
    "\n",
    "        # 색조 조절 적용\n",
    "        if apply_hue_adjust and random.random() < hue_adjust_prob:\n",
    "            aug_image = tf.image.adjust_hue(aug_image, delta=random.uniform(-0.1, 0.1))  # 색조 랜덤 조절\n",
    "            aug_image = tf.clip_by_value(aug_image, 0.0, 1.0)  # Clip hue\n",
    "\n",
    "        augmented_images.append(aug_image)  # Append aug_image directly\n",
    "\n",
    "    return augmented_images\n",
    "\n",
    "\n",
    "def gaussian_blur(image, kernel_size=(3, 3), sigma=0.1):\n",
    "  \"\"\"\n",
    "  이미지에 Gaussian Blur를 적용하는 함수\n",
    "\n",
    "  Args:\n",
    "    image: 입력 이미지 (NumPy 배열)\n",
    "    kernel_size: Gaussian Blur 커널 크기 (tuple, 기본값: (5, 5))\n",
    "    sigma: Gaussian Blur 표준 편차 (float, 기본값: 1.0)\n",
    "\n",
    "  Returns:\n",
    "    Gaussian Blur가 적용된 이미지 (NumPy 배열)\n",
    "  \"\"\"\n",
    "  blurred_image = cv2.GaussianBlur(image, kernel_size, sigma)\n",
    "  return blurred_image\n",
    "\n",
    "\n",
    "def salt_and_pepper_noise(image, amount=0.05):\n",
    "  \"\"\"\n",
    "  이미지에 Salt and Pepper 노이즈를 추가하는 함수\n",
    "\n",
    "  Args:\n",
    "    image: 입력 이미지 (NumPy 배열)\n",
    "    amount: 노이즈 비율 (float, 기본값: 0.05)\n",
    "\n",
    "  Returns:\n",
    "    Salt and Pepper 노이즈가 추가된 이미지 (NumPy 배열)\n",
    "  \"\"\"\n",
    "  noisy_image = image.copy()\n",
    "  num_salt = np.ceil(amount * image.size * 0.5)\n",
    "  coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]\n",
    "  noisy_image[tuple(coords)] = 1  # Salt 노이즈 추가\n",
    "\n",
    "  num_pepper = np.ceil(amount * image.size * 0.5)\n",
    "  coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]\n",
    "  noisy_image[tuple(coords)] = 0  # Pepper 노이즈 추가\n",
    "\n",
    "  return noisy_image\n",
    "\n",
    "\n",
    "def gaussian_noise(image, mean=0.0, std=0.05):\n",
    "    \"\"\"\n",
    "    이미지에 가우시안 노이즈를 추가합니다.\n",
    "\n",
    "    Args:\n",
    "        image: 입력 이미지 (NumPy 배열).\n",
    "        mean: 가우시안 분포의 평균 (기본값: 0.0).\n",
    "        std: 가우시안 분포의 표준 편차 (기본값: 0.05).\n",
    "\n",
    "    Returns:\n",
    "        가우시안 노이즈가 추가된 이미지.\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(loc=mean, scale=std, size=image.shape)\n",
    "    noisy_image = image + noise\n",
    "    noisy_image = np.clip(noisy_image, 0.0, 1.0)  # 픽셀 값을 유효한 범위(0-1)로 제한합니다.\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "class JellyfishClassifier:\n",
    "    def __init__(self, \n",
    "                 num_classes, \n",
    "                 model_type='efficientnet', \n",
    "                 input_shape=(224, 224, 3),\n",
    "                 pretrained=True, \n",
    "                 metrics=None, learning_rate=0.001):\n",
    "        '''\n",
    "        해파리 컬러 이미지를 분류하는 TensorFlow 기반 분류기\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): 출력 클래스 개수\n",
    "            model_type (str): 모델 타입 ('efficientnet', 'mobilenet', 'resnet')\n",
    "            input_shape (tuple): 입력 이미지 형태 (높이, 너비, 채널)\n",
    "            pretrained (bool): 사전 학습된 가중치 사용 여부\n",
    "            metrics (list): 모델 평가 시 사용할 지표 리스트\n",
    "            learning_rate (float): 학습률\n",
    "        '''\n",
    "        # 매개변수 검증 및 저장\n",
    "        if not isinstance(num_classes, int) or num_classes <= 0:\n",
    "            raise ValueError(f\"num_classes must be positive, got {num_classes}\")\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.input_shape = input_shape\n",
    "        self.pretrained = pretrained\n",
    "        self.model_type = model_type\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # 메트릭 설정\n",
    "        self.metrics = metrics if metrics is not None else ['accuracy']\n",
    "        self._validate_metrics()\n",
    "\n",
    "        # 모델 구축\n",
    "        self.model = self._build_model()\n",
    "\n",
    "        # 학습 이력 저장소\n",
    "        self.history = None\n",
    "        self.validation_metrics = {}\n",
    "        self.kfold_results = {}\n",
    "\n",
    "    def _validate_metrics(self):\n",
    "        '''메트릭 유효성 검사'''\n",
    "        valid_metrics = ['accuracy', 'f1_score', 'entropy']\n",
    "        for metric in self.metrics:\n",
    "            if metric not in valid_metrics:\n",
    "                raise ValueError(f\"Unsupported metric: {metric}. Supported: {valid_metrics}\")\n",
    "\n",
    "\n",
    "    def _build_model(self):\n",
    "        '''모델 구축'''\n",
    "        # 모델 타입에 따른 기본 모델 생성\n",
    "        weights = 'imagenet' if self.pretrained else None\n",
    "\n",
    "        # ----- Device Selection -----\n",
    "        if tf.test.is_gpu_available():\n",
    "            device = '/GPU:0'  # Use the first available GPU\n",
    "        else:\n",
    "            device = '/CPU:0'\n",
    "\n",
    "        with tf.device(device): # Use the selected device\n",
    "\n",
    "            if self.model_type == 'efficientnet':\n",
    "                base_model = applications.EfficientNetB0(\n",
    "                    weights=weights,\n",
    "                    include_top=False,\n",
    "                    input_shape=self.input_shape)\n",
    "                # 우선 전체 레이어 동결\n",
    "                base_model.trainable = False\n",
    "                for layer in base_model.layers:  # 마지막 컨볼루션 블록(7번 블록)을 훈련 가능하게 설정\n",
    "                    if 'block7' in layer.name or 'top_conv' in layer.name:\n",
    "                        layer.trainable = True\n",
    "                x = base_model.output # Assign x here for efficientnet\n",
    "\n",
    "            elif self.model_type == 'mobilenet':\n",
    "                base_model = applications.MobileNetV2(\n",
    "                    weights=weights,\n",
    "                    include_top=False,\n",
    "                    input_shape=self.input_shape)\n",
    "                # Add normalization layer after base model\n",
    "                x = base_model.output\n",
    "                x = normalization_layer(x)\n",
    "\n",
    "            elif self.model_type == 'resnet':\n",
    "                base_model = applications.ResNet50(\n",
    "                    weights=weights,\n",
    "                    include_top=False,\n",
    "                    input_shape=self.input_shape)\n",
    "                # Add normalization layer after base model\n",
    "                x = base_model.output\n",
    "                x = normalization_layer(x)\n",
    "\n",
    "            elif self.model_type == 'vgg':\n",
    "                base_model = applications.VGG16(\n",
    "                    weights=weights, \n",
    "                    include_top=False,\n",
    "                    input_shape=self.input_shape)\n",
    "                # Add normalization layer after base model\n",
    "                x = base_model.output\n",
    "                x = normalization_layer(x)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model type: {self.model_type}\")\n",
    "\n",
    "\n",
    "            # 분류 헤드 추가 (decision head)\n",
    "            x = layers.GlobalAveragePooling2D()(x)  # Global Average Pooling: 특징 맵의 공간적 차원 축소\n",
    "\n",
    "            if self.model_type == 'vgg':\n",
    "                x = layers.Dense(256, activation='relu')(x) \n",
    "            else:\n",
    "                x = layers.Dense(512, activation='leaky_relu')(x)  # Dense Layer: 비선형 변환 및 특징 학습, ReLU 활성화 함수 사용\n",
    "                x = layers.BatchNormalization()(x) # Batch Normalization: 학습 안정화 및 속도 향상\n",
    "\n",
    "            x = layers.Dropout(0.2)(x)  # Dropout: 과적합 방지 (비율 조정 가능)\n",
    "            outputs = layers.Dense(self.num_classes, activation='softmax')(x)  # 최종 분류 레이어: 6가지 해파리 분류, Softmax 활성화 함수 사용\n",
    "\n",
    "\n",
    "            # 모델 생성\n",
    "            model = models.Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "            # 컴파일\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate) # Adam optimizer 객체 생성\n",
    "\n",
    "            model.compile(\n",
    "                optimizer=optimizer, # optimizer 객체를 전달\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "\n",
    "            return model\n",
    "\n",
    "\n",
    "    def fit(self, train_data, validation_data=None, epochs=10, batch_size=32,\n",
    "           callbacks_list=None, class_weights=None):\n",
    "        '''\n",
    "        모델 훈련\n",
    "\n",
    "        Args:\n",
    "            train_data: (X_train, y_train) 튜플 또는 제너레이터\n",
    "            validation_data: (X_val, y_val) 튜플 또는 제너레이터\n",
    "            epochs (int): 훈련 에포크 수\n",
    "            batch_size (int): 배치 크기\n",
    "            callbacks_list (list): 콜백 함수 리스트\n",
    "            class_weights (dict): 클래스 가중치\n",
    "\n",
    "        Returns:\n",
    "            self: 훈련된 분류기 객체\n",
    "        '''\n",
    "        if callbacks_list is None:\n",
    "            callbacks_list = []\n",
    "\n",
    "        # 조기 종료 추가\n",
    "        early_stopping = callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=100, restore_best_weights=True\n",
    "        )\n",
    "        callbacks_list.append(early_stopping)\n",
    "\n",
    "        # 체크포인트 추가\n",
    "        checkpoint = callbacks.ModelCheckpoint(\n",
    "            'best_jellyfish_model.h5', monitor='val_loss',\n",
    "            save_best_only=True, verbose=1\n",
    "        )\n",
    "        callbacks_list.append(checkpoint)\n",
    "\n",
    "        # 50 에포크마다 모델 저장\n",
    "        checkpoint_epochs = callbacks.ModelCheckpoint(\n",
    "            filepath='/content/drive/MyDrive/ColabNotebooks/ToyDatasets/Models/model_{epoch:02d}.h5',  # 저장될 파일 경로\n",
    "            monitor='val_loss',  # 모니터링할 지표\n",
    "            save_best_only=True,  # 최상의 모델만 저장할지 여부\n",
    "            save_freq=30, # 저장 간격 (에포크)\n",
    "            verbose=1  # 진행 상황 출력 여부\n",
    "        )\n",
    "        callbacks_list.append(checkpoint_epochs)\n",
    "\n",
    "        # tqdm 콜백 추가 및 backend 변경\n",
    "        # tqdm.tqdm.pandas()\n",
    "        tqdm.pandas(desc=\"Processing...\")  # Set pandas backend to tqdm\n",
    "        callbacks_list.append(TqdmCallback(verbose=1))\n",
    "\n",
    "        # lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        #     monitor='val_loss', # We monitor the validation loss to decide when to reduce the learning rate.\n",
    "        #     factor=0.5,         #  When the validation loss plateaus, the learning rate is multiplied by this factor (reduced by half in this case).\n",
    "        #     patience=10,\n",
    "        #     verbose=1,\n",
    "        #     min_lr=1e-6\n",
    "        # )\n",
    "        # callbacks_list.append(lr_scheduler)\n",
    "\n",
    "        # 훈련 시간 증강 데이터 준비\n",
    "        if isinstance(train_data, tuple):\n",
    "            X_train, y_train = train_data\n",
    "            # AugmentationManager 에서 create_train_augmentation 메소드 호출\n",
    "            train_datagen = AugmentationManager.create_train_augmentation()     # TTA를 위한 설정\n",
    "            train_generator = train_datagen.flow(\n",
    "                X_train, y_train, batch_size=batch_size\n",
    "            )\n",
    "            validation_generator = None\n",
    "\n",
    "            if validation_data:\n",
    "                X_val, y_val = validation_data\n",
    "                val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "                validation_generator = val_datagen.flow(\n",
    "                    X_val, y_val, batch_size=batch_size, shuffle=False\n",
    "                )\n",
    "        else:\n",
    "            # 이미 제너레이터인 경우\n",
    "            train_generator = train_data\n",
    "            validation_generator = validation_data\n",
    "\n",
    "        # 검증 시간 증강 데이터 준비\n",
    "        if validation_data:\n",
    "            X_val, y_val = validation_data\n",
    "\n",
    "            # VTA를 위한 ImageDataGenerator 생성\n",
    "            val_datagen = AugmentationManager.create_test_augmentation(n_augmentations=1)  # 예: 가벼운 증강 적용\n",
    "\n",
    "            # 검증 데이터 제너레이터 생성\n",
    "            validation_generator = val_datagen[0].flow(  # 기본 증강만 적용\n",
    "                X_val, y_val, batch_size=batch_size, shuffle=False\n",
    "            )\n",
    "        else:\n",
    "            validation_generator = None\n",
    "\n",
    "        # 모델 훈련\n",
    "        self.history = self.model.fit(\n",
    "            train_generator,\n",
    "            epochs=epochs,\n",
    "            validation_data=validation_generator,\n",
    "            callbacks=callbacks_list, # tqdm 콜백 포함\n",
    "            class_weight=class_weights\n",
    "        )\n",
    "\n",
    "        return self\n",
    "\n",
    "    def evaluate(self, test_data, batch_size=32, use_tta=False, n_augmentations=3):\n",
    "        '''\n",
    "        모델 평가 (TTA 옵션 포함)\n",
    "\n",
    "        Args:\n",
    "            test_data: (X_test, y_test) 튜플 또는 제너레이터\n",
    "            batch_size (int): 배치 크기\n",
    "            use_tta (bool): Test Time Augmentation 사용 여부\n",
    "            n_augmentations (int): TTA에 사용할 증강 횟수\n",
    "\n",
    "        Returns:\n",
    "            dict: 평가 결과 딕셔너리\n",
    "        '''\n",
    "        # 데이터 준비\n",
    "        if isinstance(test_data, tuple):\n",
    "            X_test, y_test = test_data\n",
    "            if use_tta:\n",
    "                # TTA 사용 시 여러 데이터 제너레이터로 예측\n",
    "                tta_datagens = self.create_test_augmentation(n_augmentations)\n",
    "                tta_predictions = []\n",
    "\n",
    "                for datagen in tta_datagens:\n",
    "                    test_generator = datagen.flow(\n",
    "                        X_test, y_test, batch_size=batch_size, shuffle=False\n",
    "                    )\n",
    "                    # 예측 결과의 원-핫 인코딩 형태 저장\n",
    "                    y_pred_proba = self.model.predict(test_generator)\n",
    "                    tta_predictions.append(y_pred_proba)\n",
    "\n",
    "                # 여러 TTA 결과의 평균 계산\n",
    "                avg_predictions = np.mean(tta_predictions, axis=0)\n",
    "                y_pred = np.argmax(avg_predictions, axis=1)\n",
    "            else:\n",
    "                # 기본 평가\n",
    "                test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "                test_generator = test_datagen.flow(\n",
    "                    X_test, y_test, batch_size=batch_size, shuffle=False\n",
    "                )\n",
    "                y_pred_proba = self.model.predict(test_generator)\n",
    "                y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "            # 평가 지표 계산\n",
    "            results = {}\n",
    "            if 'accuracy' in self.metrics:\n",
    "                results['accuracy'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            if 'f1_score' in self.metrics:\n",
    "                results['f1_score'] = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "            if 'entropy' in self.metrics:\n",
    "                # 예측의 불확실성을 나타내는 엔트로피 계산\n",
    "                # 낮을수록 모델이 자신있게 예측한 것\n",
    "                epsilon = 1e-15  # 로그 계산 시 0 방지\n",
    "                entropy = -np.sum(avg_predictions * np.log2(avg_predictions + epsilon), axis=1)\n",
    "                results['entropy'] = np.mean(entropy)\n",
    "\n",
    "            # 혼동 행렬 계산\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            results['confusion_matrix'] = cm\n",
    "\n",
    "            self.validation_metrics = results\n",
    "            return results\n",
    "        else:\n",
    "            # 제너레이터인 경우 - TTA 미지원\n",
    "            results = self.model.evaluate(test_data)\n",
    "            return {'loss': results[0], 'accuracy': results[1]}\n",
    "\n",
    "    def predict(self, X, batch_size=32, use_tta=False, n_augmentations=3):\n",
    "        '''\n",
    "        예측 수행 (TTA 옵션 포함)\n",
    "\n",
    "        Args:\n",
    "            X: 입력 이미지 데이터\n",
    "            batch_size (int): 배치 크기\n",
    "            use_tta (bool): Test Time Augmentation 사용 여부\n",
    "            n_augmentations (int): TTA에 사용할 증강 횟수\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: 예측 클래스\n",
    "        '''\n",
    "        if use_tta:\n",
    "            # TTA 적용\n",
    "            tta_datagens = self.create_test_augmentation(n_augmentations)\n",
    "            tta_predictions = []\n",
    "\n",
    "            for datagen in tta_datagens:\n",
    "                test_generator = datagen.flow(\n",
    "                    X, batch_size=batch_size, shuffle=False\n",
    "                )\n",
    "                y_pred_proba = self.model.predict(test_generator)\n",
    "                tta_predictions.append(y_pred_proba)\n",
    "\n",
    "            # 여러 TTA 결과의 평균 계산\n",
    "            avg_predictions = np.mean(tta_predictions, axis=0)\n",
    "            return np.argmax(avg_predictions, axis=1)\n",
    "        else:\n",
    "            # 기본 예측\n",
    "            datagen = ImageDataGenerator(rescale=1./255)\n",
    "            test_generator = datagen.flow(\n",
    "                X, batch_size=batch_size, shuffle=False\n",
    "            )\n",
    "            y_pred_proba = self.model.predict(test_generator)\n",
    "            return np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "\n",
    "    def k_fold_cross_validation(self, X, y, n_splits=5, epochs=10, batch_size=32):\n",
    "        '''\n",
    "        K-fold 교차 검증 수행\n",
    "\n",
    "        Args:\n",
    "            X: 입력 이미지 데이터\n",
    "            y: 라벨\n",
    "            n_splits (int): 폴드 수\n",
    "            epochs (int): 훈련 에포크 수\n",
    "            batch_size (int): 배치 크기\n",
    "\n",
    "        Returns:\n",
    "            dict: 교차 검증 결과\n",
    "        '''\n",
    "        # K-fold 설정\n",
    "        kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        fold_results = {metric: [] for metric in self.metrics}\n",
    "        fold_results['loss'] = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):\n",
    "            print(f\"\\nFold {fold+1}/{n_splits}\")\n",
    "\n",
    "            # 데이터 분할\n",
    "            X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "            y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "            # 모델 재설정\n",
    "            self.model = self._build_model()\n",
    "\n",
    "            # 데이터 제너레이터 생성\n",
    "            train_datagen = self.create_train_augmentation()\n",
    "            val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "            train_generator = train_datagen.flow(\n",
    "                X_train_fold, y_train_fold, batch_size=batch_size\n",
    "            )\n",
    "            validation_generator = val_datagen.flow(\n",
    "                X_val_fold, y_val_fold, batch_size=batch_size, shuffle=False\n",
    "            )\n",
    "\n",
    "            # 모델 훈련\n",
    "            callbacks_list = [\n",
    "                callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "            ]\n",
    "\n",
    "            history = self.model.fit(\n",
    "                train_generator,\n",
    "                epochs=epochs,\n",
    "                validation_data=validation_generator,\n",
    "                callbacks=callbacks_list,\n",
    "                verbose=1\n",
    "            )\n",
    "\n",
    "            # 폴드 평가\n",
    "            val_results = self.evaluate((X_val_fold, y_val_fold), batch_size=batch_size)\n",
    "\n",
    "            # 결과 저장\n",
    "            fold_results['loss'].append(val_results.get('loss', history.history['val_loss'][-1]))\n",
    "\n",
    "            for metric in self.metrics:\n",
    "                if metric in val_results:\n",
    "                    fold_results[metric].append(val_results[metric])\n",
    "\n",
    "        # 평균 및 표준편차 계산\n",
    "        results = {}\n",
    "        for metric in fold_results:\n",
    "            results[f'{metric}_mean'] = np.mean(fold_results[metric])\n",
    "            results[f'{metric}_std'] = np.std(fold_results[metric])\n",
    "            results[f'{metric}_values'] = fold_results[metric]\n",
    "\n",
    "        self.kfold_results = results\n",
    "        return results\n",
    "\n",
    "    def plot_confusion_matrix(self, class_names=None):\n",
    "        '''\n",
    "        혼동 행렬 시각화\n",
    "\n",
    "        Args:\n",
    "            class_names (list): 클래스 이름 리스트\n",
    "        '''\n",
    "        if 'confusion_matrix' not in self.validation_metrics:\n",
    "            print(\"No confusion matrix available. Run evaluate() first.\")\n",
    "            return\n",
    "\n",
    "        cm = self.validation_metrics['confusion_matrix']\n",
    "\n",
    "        if class_names is None:\n",
    "            class_names = [f'Class {i}' for i in range(self.num_classes)]\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        '''학습 이력 시각화'''\n",
    "        if self.history is None:\n",
    "            print(\"No training history available. Train the model first.\")\n",
    "            return\n",
    "\n",
    "        # 손실 그래프\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.history.history['loss'], label='Training Loss')\n",
    "        if 'val_loss' in self.history.history:\n",
    "            plt.plot(self.history.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # 정확도 그래프\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.history.history['accuracy'], label='Training Accuracy')\n",
    "        if 'val_accuracy' in self.history.history:\n",
    "            plt.plot(self.history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        '''모델 저장'''\n",
    "        self.model.save(filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        '''모델 불러오기'''\n",
    "        self.model = tf.keras.models.load_model(filepath)\n",
    "        print(f\"Model loaded from {filepath}\")\n",
    "\n",
    "\n",
    "def count_images_per_class(folder_path):\n",
    "    \"\"\"\n",
    "    특정 폴더 내의 클래스별 이미지 개수를 셉니다.\n",
    "\n",
    "    Args:\n",
    "        folder_path: 이미지가 있는 폴더 경로\n",
    "\n",
    "    Returns:\n",
    "        클래스별 이미지 개수를 담은 딕셔너리\n",
    "    \"\"\"\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(folder_path):\n",
    "        class_folder = os.path.join(folder_path, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            class_counts[class_name] = len(os.listdir(class_folder))\n",
    "    return class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhY4XF7Ouhpt"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1h2qCB-ju6EX",
    "outputId": "d7517b09-7451-488a-ede9-6f6cea30ebdf"
   },
   "outputs": [],
   "source": [
    "# 구글 드라이브 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5joceYtBolpY",
    "outputId": "da8bd628-1c54-44d1-8d20-846b13011a78"
   },
   "outputs": [],
   "source": [
    "\n",
    "base_path = \"/content/drive/MyDrive/Colab Notebooks/ToyDatasets\"\n",
    "\n",
    "# 원본 데이터셋의 경로 설정\n",
    "base_data_path = base_path + \"/jellyfish-dataset/Train_Test_Valid\"\n",
    "\n",
    "train_path = base_data_path + \"/Train\"\n",
    "val_path = base_data_path + \"/valid\"\n",
    "test_path = base_data_path + \"/test\"\n",
    "\n",
    "\n",
    "# 클린 데이터셋의 경로 설정\n",
    "base_clean_data_path = base_path + \"/jellyfish-dataset/Clean_dataset\"\n",
    "\n",
    "clean_train_path = base_clean_data_path + \"/Train\"\n",
    "clean_val_path = base_clean_data_path + \"/valid\"\n",
    "clean_test_path = base_clean_data_path + \"/test\"\n",
    "\n",
    "\n",
    "print(f\"원본 데이터셋 경로:\")\n",
    "print(train_path)\n",
    "print(val_path)\n",
    "print(test_path)\n",
    "print()\n",
    "print(f\"클린 데이터셋 경로:\")\n",
    "print(clean_train_path)\n",
    "print(clean_val_path)\n",
    "print(clean_test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1MG7w9OqJTh"
   },
   "source": [
    "### Prepare Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOXUCA5cz3PK"
   },
   "outputs": [],
   "source": [
    "img_size = (224, 224)  # 일반적인 CNN 입력 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOyyNWo9z4qI"
   },
   "source": [
    "#### Option 1 : 원본 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRu6nD0eoRB6",
    "outputId": "3887ad30-ee80-4e51-d020-8841c856117d"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 데이터 로드\n",
    "X_train, y_train, class_dict = load_dataset_from_directory(train_path, img_size=img_size)\n",
    "X_test, y_test, _ = load_dataset_from_directory(test_path, img_size=img_size)\n",
    "X_valid, y_valid, _ = load_dataset_from_directory(val_path, img_size=img_size)\n",
    "\n",
    "# 데이터 정보 출력\n",
    "print(f\"클래스 정보: {class_dict}\")\n",
    "print(f\"훈련 데이터: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"테스트 데이터: {X_test.shape}, {y_test.shape}\")\n",
    "print(f\"검증 데이터: {X_valid.shape}, {y_valid.shape}\")\n",
    "\n",
    "choose_train_path = train_path\n",
    "choose_val_path = val_path\n",
    "choose_test_path = test_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iqALLUh0TvP"
   },
   "source": [
    "#### Option 2 : 클린 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1srOGduY1rae",
    "outputId": "95442464-fcd6-403d-e3b2-b1cc926d528c"
   },
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "X_train, y_train, class_dict = load_dataset_from_directory(clean_train_path, img_size=img_size)\n",
    "X_test, y_test, _ = load_dataset_from_directory(clean_test_path, img_size=img_size)\n",
    "X_valid, y_valid, _ = load_dataset_from_directory(clean_val_path, img_size=img_size)\n",
    "\n",
    "# 데이터 정보 출력\n",
    "print(f\"클래스 정보: {class_dict}\")\n",
    "print(f\"훈련 데이터: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"테스트 데이터: {X_test.shape}, {y_test.shape}\")\n",
    "print(f\"검증 데이터: {X_valid.shape}, {y_valid.shape}\")\n",
    "\n",
    "choose_train_path = clean_train_path\n",
    "choose_val_path = clean_val_path\n",
    "choose_test_path = clean_test_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LE2rYCEKoQ_G",
    "outputId": "cc806642-89e3-414f-8674-4e43a8d71b9b"
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_path와 val_path에서 클래스별 이미지 개수 세기\n",
    "train_counts = count_images_per_class(choose_train_path)\n",
    "val_counts = count_images_per_class(choose_val_path)\n",
    "test_counts = count_images_per_class(choose_test_path)\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({'train': train_counts, 'val': val_counts, 'test': test_counts})\n",
    "\n",
    "# NaN 값을 0으로 채우기\n",
    "df = df.fillna(0).astype(int)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"원본 이미지 개수:\\n{df}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "id": "RTjb_moroQ50",
    "outputId": "197975b5-2589-417f-ac74-a630f007f956"
   },
   "outputs": [],
   "source": [
    "# 원본 이미지 확인\n",
    "# 9개의 랜덤 이미지 추출\n",
    "random_indices = np.random.choice(X_train.shape[0], size=9, replace=False)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "  ax.imshow(X_train[random_indices[i]])\n",
    "  ax.set_title(list(class_dict.keys())[y_train[random_indices[i]]])\n",
    "  ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVGssO6aqYKo"
   },
   "source": [
    "### 증강\n",
    "\n",
    "Generate pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IC4zhcnLoQ3Q"
   },
   "outputs": [],
   "source": [
    "# 증강 파이프라인 생성\n",
    "augmentation_transforms = AugmentationManager.create_train_augmentation(\n",
    "    rotation_range=20,          # -40도 +40도 사이에서 무작위 회전\n",
    "    width_shift_range=0.1,      # 이미지 가로 방향으로 원본 너비의 20%까지 무작위 이동\n",
    "    height_shift_range=0.1,     # 이미지 세로 방향으로 원본 높이의 20%까지 무작위 이동\n",
    "    zoom_range=0.2,             # 이미지를 0.8배에서 1.2배 사이로 무작위 확대/축소\n",
    "    horizontal_flip=True        # 이미지 좌우 반전\n",
    "    # brightness_range=(0.8, 1.2),\n",
    "    # contrast_range=(0.8, 1.2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnsEENQqqemb"
   },
   "source": [
    "### Confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Q-Gwv4HQoQ08",
    "outputId": "8dd2c0ab-c326-4a79-8552-70d859665000"
   },
   "outputs": [],
   "source": [
    "# 증강 이미지 확인하기\n",
    "# 랜덤 이미지 선택 및 증강\n",
    "image = X_train[np.random.randint(len(X_train))]\n",
    "augs = apply_augmentation(image, augmentation_transforms, num_samples=24)\n",
    "\n",
    "# 시각화\n",
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "fig.suptitle('Original example image and its augmented variants')\n",
    "\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    ax.axis('off')\n",
    "    if i == 0:\n",
    "        # 원본 이미지 표시\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            ax.imshow(image)  # 컬러 이미지\n",
    "        else:\n",
    "            ax.imshow(image, cmap='Greys')  # 흑백 이미지\n",
    "        ax.set_title('Original')\n",
    "    elif i-1 < len(augs):\n",
    "        # 증강된 이미지 표시\n",
    "        if len(augs[i-1].shape) == 3 and augs[i-1].shape[2] == 3:\n",
    "            ax.imshow(augs[i-1])  # 컬러 이미지\n",
    "        else:\n",
    "            ax.imshow(augs[i-1], cmap='Greys')  # 흑백 이미지\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IYVtL7Uxv1e-",
    "outputId": "38607f63-f6c3-4667-b1b0-d2b092f78294"
   },
   "outputs": [],
   "source": [
    "def get_class_labels(data_path):\n",
    "  \"\"\"\n",
    "  디렉토리 구조를 기반으로 클래스 레이블 추론\n",
    "\n",
    "  Args:\n",
    "    data_path: 클래스 별 하위폴더를 포함하는 데이터셋의 상위 디렉토리\n",
    "\n",
    "  Returns:\n",
    "    클래스 레이블을 딕셔너리로 반환\n",
    "  \"\"\"\n",
    "  class_labels = {}\n",
    "  for folder_name in os.listdir(data_path):\n",
    "    folder_path = os.path.join(data_path, folder_name)\n",
    "    if os.path.isdir(folder_path):\n",
    "      class_labels[folder_name] = folder_name  # Assuming directory name is the class label\n",
    "  return class_labels\n",
    "\n",
    "# Get class labels for train and validation sets\n",
    "train_labels = get_class_labels(choose_train_path)\n",
    "val_labels = get_class_labels(choose_val_path)\n",
    "\n",
    "print(\"Train Labels:\", train_labels)\n",
    "print(\"Validation Labels:\", val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0r_vewG4c0Q"
   },
   "source": [
    "## 분류기 초기 설정 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pZHNBWQi2P_q",
    "outputId": "35f08384-1afb-48e1-e332-55a5f992820a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalization_layer(input_tensor):\n",
    "    \"\"\"\n",
    "    Normalizes the input tensor using BatchNormalization.\n",
    "\n",
    "    Args:\n",
    "        input_tensor: The input tensor to normalize.\n",
    "\n",
    "    Returns:\n",
    "        The normalized tensor.\n",
    "    \"\"\"\n",
    "    return layers.BatchNormalization()(input_tensor)\n",
    "\n",
    "\"\"\"\n",
    "원규님 model option\n",
    "model = vgg16\n",
    "learning_rate: 0.001\n",
    "batch_size = 16\n",
    "epochs = 15\n",
    "optimizer = adam\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 1. 분류기 초기화\n",
    "classifier = JellyfishClassifier(\n",
    "    num_classes=6,  # 해파리 클래스 수\n",
    "    model_type='mobilenet',  # 'efficientnet', 'mobilenet', 'resnet','vgg16' 중 선택\n",
    "    pretrained=True,  # ImageNet 가중치 사용\n",
    "    metrics=['accuracy', 'f1_score'],  # 평가 지표에서 entropy 제거 -> evaluate 에서 계산\n",
    "    # learning_rate=1e-5  # 학습률 조정\n",
    ")\n",
    "# 2. 분류기 인스턴스에서 모델 서머리 출력:\n",
    "classifier.model.summary()\n",
    "\n",
    "def get_vgg16_model():\n",
    "    return JellyfishClassifier(\n",
    "        num_classes=6,\n",
    "        model_type='vgg16',\n",
    "        pretrained=True,\n",
    "        metrics=['accuracy', 'f1_score'],\n",
    "        learning_rate= 0.001 #1e-3\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850,
     "referenced_widgets": [
      "e37d5bffb2c54eb9b2b525f42099e3ef",
      "e4ac7c96ae084449b0b79b4ec09be8b1",
      "ffdb668f9932487baeac67c1e1a27b88",
      "178257feba22432aaeaf95f4daf2bbe6",
      "d8bacb19c62a44638d344a236c0d8d8a",
      "a15440b9fe3546248e73b72ab8025a3f",
      "ce471f9c09654773a46db08d00e546ad",
      "6c80969e23e84ab7a975eff04ed8c83f",
      "d09e6442c1204b749abc86f461aaf525",
      "86ef49197a964c428ce5deea6ffbca52",
      "2916ac6e0f9b46a6a7e335ad7e02d763",
      "0f13b60b90354903b31b529df0805547",
      "740ca07e1b654b5bb0411b74a04d99d5",
      "ba4ea0a28f8047fbbd119d5daa86661a",
      "181860461fd14b91b700ecd58885dcf2",
      "045ad3ef2de74304b0cb01c34a95e257",
      "08ef36fdebca4ab6afd3635187e24359",
      "ed9cd6d8c24d4993b7e2caddd0ea230a",
      "1c4aef5d124f42e69f690a1254e2ab7b",
      "44b4900e322040babf46230380d0aba1",
      "d0d50bc0c6bf4f75a862e512c5cd6336",
      "09a768a8b2ee47d5abf3d5776451487d"
     ]
    },
    "id": "LrHZ6n6Q4mGE",
    "outputId": "f0226f46-9f30-4277-deac-21b8d52a2232"
   },
   "outputs": [],
   "source": [
    "# 3. 모델 훈련\n",
    "# JellyfishClassifier 클래스 내부의 fit 메서드에서 TTA 자동 적용\n",
    "classifier.fit(\n",
    "    (X_train, y_train),  # 또는 train_generator\n",
    "    validation_data=(X_valid, y_valid),  # 또는 val_generator\n",
    "    epochs=10,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceBgJwP84cW2"
   },
   "source": [
    "## 훈련 검증 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942
    },
    "id": "157hqHdI4u5G",
    "outputId": "2c06edea-3a66-4c8a-e792-2e93495599b7"
   },
   "outputs": [],
   "source": [
    "# 훈련 검증 시각화\n",
    "# classifier 객체가 검증 지표를 담은 history 를 가지고 있음\n",
    "history = classifier.history\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set(title='Training and Validation Accuracy', xlabel='Epoch', ylabel='Accuracy')\n",
    "ax.grid()\n",
    "ax.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "ax.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set(title='Training and Validation Loss Values', xlabel='Epoch', ylabel='Loss')\n",
    "ax.grid()\n",
    "ax.plot(history.history['loss'], label='Train Loss')\n",
    "ax.plot(history.history['val_loss'], label='Validation Loss')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "id": "-OpzYcjw41Z3",
    "outputId": "a5ecd619-91c5-48b9-9234-4f5eb4396d29"
   },
   "outputs": [],
   "source": [
    "# 'classifier' 객체가 학습 지표를 포함한 history 속성을 가지고 있다고 가정\n",
    "history = classifier.history\n",
    "\n",
    "# 학습 및 검증 정확도(accuracy) 그래프 그리기\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])  # history.history를 사용해 학습 정확도에 접근\n",
    "plt.plot(history.history['val_accuracy']) # history.history를 사용해 검증 정확도에 접근\n",
    "plt.title('Model accuracy')# 그래프 제목 설정\n",
    "plt.ylabel('Accuracy')  # y축 레이블 설정\n",
    "plt.xlabel('Epoch') # x축 레이블 설정\n",
    "plt.legend(['Train', 'Validation'], loc='upper left') # 범례 추가\n",
    "\n",
    "# 학습 및 검증 손실(loss) 그래프 그리기\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss']) # history.history를 사용해 학습 손실에 접근\n",
    "plt.plot(history.history['val_loss']) # history.history를 사용해 검증 손실에 접근\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.tight_layout() # 그래프 간격 조정\n",
    "plt.show() # 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ptHJUyqf46uf",
    "outputId": "bff2735b-03c7-4013-ade8-af8caa2f37b5"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = datagen.flow(\n",
    "    X_train, batch_size=8, shuffle=False\n",
    ")\n",
    "y_pred_proba = classifier.model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0PbBZo_c48-Y",
    "outputId": "ed874218-d0bc-4bdb-997d-a458f9f48a29"
   },
   "outputs": [],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhDfrPC65HUZ",
    "outputId": "309df8ce-1719-4c94-c404-ab9dcc69968e"
   },
   "outputs": [],
   "source": [
    "classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STVeSmj45LR6"
   },
   "outputs": [],
   "source": [
    "# 사용 예시\n",
    "\"\"\"\n",
    "# 1. 분류기 초기화\n",
    "classifier = JellyfishClassifier(\n",
    "    num_classes=5,  # 해파리 클래스 수\n",
    "    model_type='efficientnet',  # 'efficientnet', 'mobilenet', 'resnet' 중 선택\n",
    "    pretrained=True,  # ImageNet 가중치 사용\n",
    "    metrics=['accuracy', 'f1_score', 'entropy'],  # 평가 지표\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "# 2. 데이터 준비 (예시)\n",
    "# NumPy 배열로부터 직접 로드\n",
    "X_train, y_train = load_jellyfish_data('train')  # 데이터 로드 함수 (직접 구현 필요)\n",
    "X_val, y_val = load_jellyfish_data('val')\n",
    "X_test, y_test = load_jellyfish_data('test')\n",
    "\n",
    "# 또는 디렉토리에서 로드\n",
    "train_datagen = classifier.create_train_augmentation()\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data/jellyfish/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'data/jellyfish/val',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# 3. 모델 훈련\n",
    "classifier.fit(\n",
    "    (X_train, y_train),  # 또는 train_generator\n",
    "    validation_data=(X_val, y_val),  # 또는 val_generator\n",
    "    epochs=20,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# 4. 모델 평가 (TTA 적용)\n",
    "results = classifier.evaluate(\n",
    "    (X_test, y_test),\n",
    "    use_tta=True,\n",
    "    n_augmentations=3\n",
    ")\n",
    "print(f\"Test results: {results}\")\n",
    "\n",
    "# 5. K-fold 교차 검증\n",
    "kfold_results = classifier.k_fold_cross_validation(\n",
    "    X_train, y_train, n_splits=5, epochs=10\n",
    ")\n",
    "print(f\"K-fold results: {kfold_results}\")\n",
    "\n",
    "# 6. 시각화\n",
    "classifier.plot_confusion_matrix(class_names=['종류1', '종류2', '종류3', '종류4', '종류5'])\n",
    "classifier.plot_training_history()\n",
    "\n",
    "# 7. 모델 저장 및 로드\n",
    "classifier.save_model('jellyfish_classifier.h5')\n",
    "classifier.load_model('jellyfish_classifier.h5')\n",
    "\n",
    "# 8. 새 이미지 예측 (TTA 적용)\n",
    "new_images = load_new_images()  # 새 이미지 로드\n",
    "predictions = classifier.predict(new_images, use_tta=True)\n",
    "print(f\"Predictions: {predictions}\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "045ad3ef2de74304b0cb01c34a95e257": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "08ef36fdebca4ab6afd3635187e24359": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09a768a8b2ee47d5abf3d5776451487d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f13b60b90354903b31b529df0805547": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_740ca07e1b654b5bb0411b74a04d99d5",
       "IPY_MODEL_ba4ea0a28f8047fbbd119d5daa86661a",
       "IPY_MODEL_181860461fd14b91b700ecd58885dcf2"
      ],
      "layout": "IPY_MODEL_045ad3ef2de74304b0cb01c34a95e257"
     }
    },
    "178257feba22432aaeaf95f4daf2bbe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86ef49197a964c428ce5deea6ffbca52",
      "placeholder": "​",
      "style": "IPY_MODEL_2916ac6e0f9b46a6a7e335ad7e02d763",
      "value": " 10/10 [02:09&lt;00:00,  7.71s/epoch, accuracy=0.224, loss=2.01, val_accuracy=0.169, val_loss=1.86]"
     }
    },
    "181860461fd14b91b700ecd58885dcf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0d50bc0c6bf4f75a862e512c5cd6336",
      "placeholder": "​",
      "style": "IPY_MODEL_09a768a8b2ee47d5abf3d5776451487d",
      "value": " 29.0/29.0 [00:04&lt;00:00, 6.06batch/s, accuracy=0.224, loss=2.01]"
     }
    },
    "1c4aef5d124f42e69f690a1254e2ab7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2916ac6e0f9b46a6a7e335ad7e02d763": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44b4900e322040babf46230380d0aba1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c80969e23e84ab7a975eff04ed8c83f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "740ca07e1b654b5bb0411b74a04d99d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08ef36fdebca4ab6afd3635187e24359",
      "placeholder": "​",
      "style": "IPY_MODEL_ed9cd6d8c24d4993b7e2caddd0ea230a",
      "value": "100%"
     }
    },
    "86ef49197a964c428ce5deea6ffbca52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a15440b9fe3546248e73b72ab8025a3f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba4ea0a28f8047fbbd119d5daa86661a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c4aef5d124f42e69f690a1254e2ab7b",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_44b4900e322040babf46230380d0aba1",
      "value": 29
     }
    },
    "ce471f9c09654773a46db08d00e546ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d09e6442c1204b749abc86f461aaf525": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d0d50bc0c6bf4f75a862e512c5cd6336": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8bacb19c62a44638d344a236c0d8d8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e37d5bffb2c54eb9b2b525f42099e3ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e4ac7c96ae084449b0b79b4ec09be8b1",
       "IPY_MODEL_ffdb668f9932487baeac67c1e1a27b88",
       "IPY_MODEL_178257feba22432aaeaf95f4daf2bbe6"
      ],
      "layout": "IPY_MODEL_d8bacb19c62a44638d344a236c0d8d8a"
     }
    },
    "e4ac7c96ae084449b0b79b4ec09be8b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a15440b9fe3546248e73b72ab8025a3f",
      "placeholder": "​",
      "style": "IPY_MODEL_ce471f9c09654773a46db08d00e546ad",
      "value": "100%"
     }
    },
    "ed9cd6d8c24d4993b7e2caddd0ea230a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ffdb668f9932487baeac67c1e1a27b88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c80969e23e84ab7a975eff04ed8c83f",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d09e6442c1204b749abc86f461aaf525",
      "value": 10
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
